{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "356b684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbcc1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    \"\"\"Handles loading and processing MIDI data for training.\"\"\"\n",
    "    \n",
    "    def __init__(self, midi_folder='Data', num_files=20):\n",
    "        self.midi_folder = midi_folder\n",
    "        self.num_files = num_files\n",
    "\n",
    "    def load_midi_files(self):\n",
    "        \"\"\"Loads MIDI files from the specified folder up to a specified maximum number.\"\"\"\n",
    "        path = os.path.join(self.midi_folder, '*.mid')\n",
    "        files = glob(path)\n",
    "        return files[:self.num_files]\n",
    "\n",
    "    def get_notes(self):\n",
    "        \"\"\"Extracts notes and chords from MIDI files.\"\"\"\n",
    "        notes = []\n",
    "        for file in self.load_midi_files():\n",
    "            midi = converter.parse(file)\n",
    "            parts = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = parts.parts[0].recurse() if parts else midi.flat.notes\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "        return notes\n",
    "\n",
    "    def prepare_sequences(self, notes, sequence_length=100):\n",
    "        \"\"\"Prepares training sequences for the model.\"\"\"\n",
    "        pitchnames = sorted(set(notes))\n",
    "        note_to_int = {note: number for number, note in enumerate(pitchnames)}\n",
    "        network_input = []\n",
    "        network_output = []\n",
    "        \n",
    "        for i in range(len(notes) - sequence_length):\n",
    "            sequence_in = notes[i: i + sequence_length]\n",
    "            sequence_out = notes[i + sequence_length]\n",
    "            network_input.append([note_to_int[char] for char in sequence_in])\n",
    "            network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "        n_patterns = len(network_input)\n",
    "        network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "        network_input = network_input / float(len(pitchnames))\n",
    "        network_output = to_categorical(network_output, num_classes=len(pitchnames))\n",
    "        \n",
    "        return network_input, network_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa13a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicModel:\n",
    "    \"\"\"Builds and trains a neural network for music generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='Model', lstm_units=(128, 128), dropout_rates=(0.2, 0.3), dense_units=256):\n",
    "        self.model_path = model_path\n",
    "        self.lstm_units = lstm_units\n",
    "        self.dropout_rates = dropout_rates\n",
    "        self.dense_units = dense_units\n",
    "        if not os.path.exists(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "\n",
    "    def create_network(self, input_shape, n_vocab):\n",
    "        \"\"\"Creates the LSTM network model.\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=input_shape))  # Explicit input layer\n",
    "        model.add(LSTM(self.lstm_units[0], return_sequences=True))\n",
    "        model.add(Dropout(self.dropout_rates[0]))\n",
    "        model.add(LSTM(self.lstm_units[1]))\n",
    "        model.add(Dropout(self.dropout_rates[1]))\n",
    "        model.add(Dense(self.dense_units))\n",
    "        model.add(Dense(n_vocab, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def train(self, network_input, network_output, epochs=50, batch_size=64):\n",
    "        \"\"\"Trains the model and saves the best performing model.\"\"\"\n",
    "        model = self.create_network((network_input.shape[1], network_input.shape[2]), network_output.shape[1])\n",
    "        filepath = os.path.join(self.model_path, f'weights.best.music.keras')\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "        model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc49a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenerator:\n",
    "    \"\"\"Generates music using the trained model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='Model', output_path='Output/output.mid'):\n",
    "        self.model_path = model_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\"Loads the trained model.\"\"\"\n",
    "        return load_model(os.path.join(self.model_path, 'weights.best.music.keras'))\n",
    "\n",
    "    def generate_music(self, model, notes, n_vocab, length=500, temperature=1.0):\n",
    "        \"\"\"Generates a sequence of music notes.\"\"\"\n",
    "        int_to_note = {number: note for number, note in enumerate(sorted(set(notes)))}\n",
    "        pattern = np.random.randint(0, n_vocab, size=(100,)).tolist()\n",
    "        prediction_output = []\n",
    "\n",
    "        for note_index in range(length):\n",
    "            prediction_input = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n",
    "            prediction = model.predict(prediction_input, verbose=0).astype('float64')\n",
    "            prediction = np.log(prediction + 1e-7) / temperature  # Smoothing\n",
    "            exp_preds = np.exp(prediction)\n",
    "            prediction = exp_preds / np.sum(exp_preds)\n",
    "            index = np.random.choice(range(n_vocab), p=prediction[0])\n",
    "            result = int_to_note[index]\n",
    "            prediction_output.append(result)\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:]\n",
    "\n",
    "        return prediction_output\n",
    "    \n",
    "    def create_midi(self, prediction_output):\n",
    "        \"\"\"Converts the generated note sequence into a MIDI file.\"\"\"\n",
    "        offset = 0\n",
    "        output_notes = []\n",
    "\n",
    "        for pattern in prediction_output:\n",
    "            # Handling chords\n",
    "            if ('.' in pattern) or pattern.isdigit():\n",
    "                notes_in_chord = pattern.split('.')\n",
    "                notes = [note.Note(int(n)) for n in notes_in_chord]\n",
    "                new_chord = chord.Chord(notes)\n",
    "                new_chord.offset = offset\n",
    "                output_notes.append(new_chord)\n",
    "            else: # Handling single notes\n",
    "                new_note = note.Note(pattern)\n",
    "                new_note.offset = offset\n",
    "                output_notes.append(new_note)\n",
    "\n",
    "            offset += 0.5\n",
    "\n",
    "        midi_stream = stream.Stream(output_notes)\n",
    "        midi_stream.write('midi', fp=self.output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c9cd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicPlayer:\n",
    "    \"\"\"Plays MIDI music files.\"\"\"\n",
    "    def __init__(self, midi_file_path):\n",
    "        self.midi_file_path = midi_file_path\n",
    "\n",
    "    def play_midi(self):\n",
    "        \"\"\"Uses music21 to play a MIDI file.\"\"\"\n",
    "        from music21 import midi\n",
    "        midi_stream = converter.parse(self.midi_file_path)\n",
    "        sp = midi.realtime.StreamPlayer(midi_stream)\n",
    "        sp.play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2a72df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 4.0917\n",
      "Epoch 1: loss improved from inf to 3.95932, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 129ms/step - loss: 4.0909\n",
      "Epoch 2/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 3.8479\n",
      "Epoch 2: loss improved from 3.95932 to 3.82737, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - loss: 3.8477\n",
      "Epoch 3/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 3.7826\n",
      "Epoch 3: loss improved from 3.82737 to 3.76781, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 3.7825\n",
      "Epoch 4/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.7391\n",
      "Epoch 4: loss improved from 3.76781 to 3.73371, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - loss: 3.7391\n",
      "Epoch 5/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 3.7206\n",
      "Epoch 5: loss improved from 3.73371 to 3.71877, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 3.7206\n",
      "Epoch 6/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 3.7257\n",
      "Epoch 6: loss improved from 3.71877 to 3.71293, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 140ms/step - loss: 3.7256\n",
      "Epoch 7/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.6804\n",
      "Epoch 7: loss improved from 3.71293 to 3.67785, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 139ms/step - loss: 3.6804\n",
      "Epoch 8/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.6507\n",
      "Epoch 8: loss improved from 3.67785 to 3.65527, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 130ms/step - loss: 3.6507\n",
      "Epoch 9/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 3.6263\n",
      "Epoch 9: loss improved from 3.65527 to 3.62690, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 141ms/step - loss: 3.6263\n",
      "Epoch 10/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 3.6062\n",
      "Epoch 10: loss improved from 3.62690 to 3.60903, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - loss: 3.6062\n",
      "Epoch 11/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.5808\n",
      "Epoch 11: loss improved from 3.60903 to 3.58399, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 3.5808\n",
      "Epoch 12/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.5605\n",
      "Epoch 12: loss improved from 3.58399 to 3.56610, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - loss: 3.5606\n",
      "Epoch 13/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.5489\n",
      "Epoch 13: loss improved from 3.56610 to 3.55104, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 3.5489\n",
      "Epoch 14/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.5165\n",
      "Epoch 14: loss improved from 3.55104 to 3.52039, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - loss: 3.5165\n",
      "Epoch 15/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.4824\n",
      "Epoch 15: loss improved from 3.52039 to 3.49025, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 137ms/step - loss: 3.4824\n",
      "Epoch 16/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.4768\n",
      "Epoch 16: loss improved from 3.49025 to 3.47408, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 3.4768\n",
      "Epoch 17/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.4399\n",
      "Epoch 17: loss improved from 3.47408 to 3.44666, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 130ms/step - loss: 3.4400\n",
      "Epoch 18/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.4258\n",
      "Epoch 18: loss improved from 3.44666 to 3.42753, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 130ms/step - loss: 3.4259\n",
      "Epoch 19/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 3.3554\n",
      "Epoch 19: loss improved from 3.42753 to 3.39616, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - loss: 3.3556\n",
      "Epoch 20/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.3633\n",
      "Epoch 20: loss improved from 3.39616 to 3.37172, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - loss: 3.3633\n",
      "Epoch 21/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 3.2991\n",
      "Epoch 21: loss improved from 3.37172 to 3.31719, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 3.2992\n",
      "Epoch 22/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.2334\n",
      "Epoch 22: loss improved from 3.31719 to 3.23740, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 3.2334\n",
      "Epoch 23/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 3.1654\n",
      "Epoch 23: loss improved from 3.23740 to 3.18272, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 136ms/step - loss: 3.1655\n",
      "Epoch 24/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 3.0942\n",
      "Epoch 24: loss improved from 3.18272 to 3.11549, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 138ms/step - loss: 3.0944\n",
      "Epoch 25/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 3.0298\n",
      "Epoch 25: loss improved from 3.11549 to 3.04583, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 3.0299\n",
      "Epoch 26/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.9810\n",
      "Epoch 26: loss improved from 3.04583 to 2.98892, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 2.9811\n",
      "Epoch 27/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.8701\n",
      "Epoch 27: loss improved from 2.98892 to 2.89502, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 2.8702\n",
      "Epoch 28/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 2.8426\n",
      "Epoch 28: loss improved from 2.89502 to 2.85726, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 131ms/step - loss: 2.8427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.8094\n",
      "Epoch 29: loss improved from 2.85726 to 2.80825, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 2.8094\n",
      "Epoch 30/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.7621\n",
      "Epoch 30: loss improved from 2.80825 to 2.75428, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 2.7620\n",
      "Epoch 31/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2.6968\n",
      "Epoch 31: loss improved from 2.75428 to 2.70081, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - loss: 2.6968\n",
      "Epoch 32/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.6303\n",
      "Epoch 32: loss improved from 2.70081 to 2.64997, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 2.6304\n",
      "Epoch 33/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.6353\n",
      "Epoch 33: loss improved from 2.64997 to 2.63626, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 139ms/step - loss: 2.6353\n",
      "Epoch 34/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.5871\n",
      "Epoch 34: loss did not improve from 2.63626\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 2.5874\n",
      "Epoch 35/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.5932\n",
      "Epoch 35: loss improved from 2.63626 to 2.59105, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.5932\n",
      "Epoch 36/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.5029\n",
      "Epoch 36: loss improved from 2.59105 to 2.53003, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.5031\n",
      "Epoch 37/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 2.4892\n",
      "Epoch 37: loss improved from 2.53003 to 2.51108, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 2.4893\n",
      "Epoch 38/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 2.4397\n",
      "Epoch 38: loss improved from 2.51108 to 2.47126, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.4399\n",
      "Epoch 39/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.4204\n",
      "Epoch 39: loss improved from 2.47126 to 2.44342, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 2.4206\n",
      "Epoch 40/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.4058\n",
      "Epoch 40: loss improved from 2.44342 to 2.41736, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.4059\n",
      "Epoch 41/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 2.3541\n",
      "Epoch 41: loss improved from 2.41736 to 2.38702, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.3543\n",
      "Epoch 42/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 2.3288\n",
      "Epoch 42: loss improved from 2.38702 to 2.36135, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.3290\n",
      "Epoch 43/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.3254\n",
      "Epoch 43: loss improved from 2.36135 to 2.34233, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.3255\n",
      "Epoch 44/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.3338\n",
      "Epoch 44: loss improved from 2.34233 to 2.33279, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.3338\n",
      "Epoch 45/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 2.2785\n",
      "Epoch 45: loss improved from 2.33279 to 2.29571, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - loss: 2.2786\n",
      "Epoch 46/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.2618\n",
      "Epoch 46: loss improved from 2.29571 to 2.28709, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 2.2620\n",
      "Epoch 47/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 2.2254\n",
      "Epoch 47: loss improved from 2.28709 to 2.26563, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - loss: 2.2256\n",
      "Epoch 48/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.2118\n",
      "Epoch 48: loss improved from 2.26563 to 2.23345, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 126ms/step - loss: 2.2119\n",
      "Epoch 49/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 2.1785\n",
      "Epoch 49: loss improved from 2.23345 to 2.21161, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 2.1787\n",
      "Epoch 50/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 2.1713\n",
      "Epoch 50: loss improved from 2.21161 to 2.20151, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 2.1715\n",
      "Epoch 51/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.1340\n",
      "Epoch 51: loss improved from 2.20151 to 2.16335, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 137ms/step - loss: 2.1342\n",
      "Epoch 52/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2.1221\n",
      "Epoch 52: loss improved from 2.16335 to 2.14985, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 2.1223\n",
      "Epoch 53/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.0690\n",
      "Epoch 53: loss improved from 2.14985 to 2.12924, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 2.0694\n",
      "Epoch 54/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.0681\n",
      "Epoch 54: loss improved from 2.12924 to 2.11660, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 2.0684\n",
      "Epoch 55/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.0612\n",
      "Epoch 55: loss improved from 2.11660 to 2.10067, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 2.0615\n",
      "Epoch 56/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.0345\n",
      "Epoch 56: loss improved from 2.10067 to 2.08480, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - loss: 2.0348\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 2.0246\n",
      "Epoch 57: loss improved from 2.08480 to 2.06840, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 150ms/step - loss: 2.0249\n",
      "Epoch 58/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.0152\n",
      "Epoch 58: loss improved from 2.06840 to 2.04759, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 148ms/step - loss: 2.0154\n",
      "Epoch 59/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.9952\n",
      "Epoch 59: loss improved from 2.04759 to 2.02582, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - loss: 1.9954\n",
      "Epoch 60/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.0112\n",
      "Epoch 60: loss improved from 2.02582 to 2.02084, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 156ms/step - loss: 2.0113\n",
      "Epoch 61/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 1.9788\n",
      "Epoch 61: loss did not improve from 2.02084\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 160ms/step - loss: 1.9790\n",
      "Epoch 62/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.9210\n",
      "Epoch 62: loss improved from 2.02084 to 1.97795, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 156ms/step - loss: 1.9213\n",
      "Epoch 63/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.9235\n",
      "Epoch 63: loss improved from 1.97795 to 1.96844, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 154ms/step - loss: 1.9237\n",
      "Epoch 64/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.9237\n",
      "Epoch 64: loss improved from 1.96844 to 1.95130, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - loss: 1.9239\n",
      "Epoch 65/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.9019\n",
      "Epoch 65: loss improved from 1.95130 to 1.93707, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 148ms/step - loss: 1.9021\n",
      "Epoch 66/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.9258\n",
      "Epoch 66: loss did not improve from 1.93707\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - loss: 1.9261\n",
      "Epoch 67/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.8989\n",
      "Epoch 67: loss improved from 1.93707 to 1.92467, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 153ms/step - loss: 1.8990\n",
      "Epoch 68/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.8422\n",
      "Epoch 68: loss improved from 1.92467 to 1.90018, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 154ms/step - loss: 1.8425\n",
      "Epoch 69/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.8558\n",
      "Epoch 69: loss improved from 1.90018 to 1.88344, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 156ms/step - loss: 1.8560\n",
      "Epoch 70/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 2.1585\n",
      "Epoch 70: loss did not improve from 1.88344\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 201ms/step - loss: 2.1581\n",
      "Epoch 71/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 1.9381\n",
      "Epoch 71: loss did not improve from 1.88344\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 167ms/step - loss: 1.9387\n",
      "Epoch 72/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 1.9317\n",
      "Epoch 72: loss did not improve from 1.88344\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 168ms/step - loss: 1.9315\n",
      "Epoch 73/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 1.7845\n",
      "Epoch 73: loss improved from 1.88344 to 1.83519, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 175ms/step - loss: 1.7848\n",
      "Epoch 74/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.8012\n",
      "Epoch 74: loss did not improve from 1.83519\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - loss: 1.8014\n",
      "Epoch 75/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.8187\n",
      "Epoch 75: loss did not improve from 1.83519\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - loss: 1.8188\n",
      "Epoch 76/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7783\n",
      "Epoch 76: loss improved from 1.83519 to 1.79872, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 140ms/step - loss: 1.7784\n",
      "Epoch 77/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.7733\n",
      "Epoch 77: loss improved from 1.79872 to 1.78603, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 156ms/step - loss: 1.7734\n",
      "Epoch 78/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.7344\n",
      "Epoch 78: loss improved from 1.78603 to 1.76775, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 158ms/step - loss: 1.7346\n",
      "Epoch 79/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.7122\n",
      "Epoch 79: loss improved from 1.76775 to 1.75458, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 161ms/step - loss: 1.7124\n",
      "Epoch 80/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7157\n",
      "Epoch 80: loss improved from 1.75458 to 1.74330, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 140ms/step - loss: 1.7159\n",
      "Epoch 81/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.7368\n",
      "Epoch 81: loss improved from 1.74330 to 1.73599, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 1.7368\n",
      "Epoch 82/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.7489\n",
      "Epoch 82: loss did not improve from 1.73599\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 136ms/step - loss: 1.7493\n",
      "Epoch 83/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.6884\n",
      "Epoch 83: loss improved from 1.73599 to 1.70773, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 1.6885\n",
      "Epoch 84/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.6417\n",
      "Epoch 84: loss improved from 1.70773 to 1.68342, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 136ms/step - loss: 1.6420\n",
      "Epoch 85/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.6767\n",
      "Epoch 85: loss did not improve from 1.68342\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.6768\n",
      "Epoch 86/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.6431\n",
      "Epoch 86: loss improved from 1.68342 to 1.67079, saving model to Model/weights.best.music.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.6433\n",
      "Epoch 87/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.6263\n",
      "Epoch 87: loss improved from 1.67079 to 1.66295, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 1.6265\n",
      "Epoch 88/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.6099\n",
      "Epoch 88: loss improved from 1.66295 to 1.65006, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 133ms/step - loss: 1.6101\n",
      "Epoch 89/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.6132\n",
      "Epoch 89: loss improved from 1.65006 to 1.64754, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 139ms/step - loss: 1.6134\n",
      "Epoch 90/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.5891\n",
      "Epoch 90: loss improved from 1.64754 to 1.62071, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 135ms/step - loss: 1.5893\n",
      "Epoch 91/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.5949\n",
      "Epoch 91: loss did not improve from 1.62071\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 127ms/step - loss: 1.5954\n",
      "Epoch 92/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.6037\n",
      "Epoch 92: loss did not improve from 1.62071\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - loss: 1.6039\n",
      "Epoch 93/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.5807\n",
      "Epoch 93: loss improved from 1.62071 to 1.59265, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 1.5808\n",
      "Epoch 94/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.5321\n",
      "Epoch 94: loss improved from 1.59265 to 1.58638, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 1.5324\n",
      "Epoch 95/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.5571\n",
      "Epoch 95: loss did not improve from 1.58638\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 1.5573\n",
      "Epoch 96/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.6195\n",
      "Epoch 96: loss did not improve from 1.58638\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 138ms/step - loss: 1.6195\n",
      "Epoch 97/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.4844\n",
      "Epoch 97: loss improved from 1.58638 to 1.55310, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 134ms/step - loss: 1.4848\n",
      "Epoch 98/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.4998\n",
      "Epoch 98: loss improved from 1.55310 to 1.54813, saving model to Model/weights.best.music.keras\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 132ms/step - loss: 1.5001\n",
      "Epoch 99/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.6509\n",
      "Epoch 99: loss did not improve from 1.54813\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 142ms/step - loss: 1.6529\n",
      "Epoch 100/100\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.1712\n",
      "Epoch 100: loss did not improve from 1.54813\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 136ms/step - loss: 2.1698\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Implementing the Neural Network and Training it\"\"\"\n",
    "data_handler = DataHandler()\n",
    "\n",
    "notes = data_handler.get_notes()\n",
    "if len(notes) > 100:\n",
    "    n_vocab = len(set(notes))\n",
    "    network_input, network_output = data_handler.prepare_sequences(notes)\n",
    "\n",
    "    model_trainer = MusicModel()\n",
    "\n",
    "    model_trainer.train(network_input, network_output, epochs=100)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough notes to proceed with training and music generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae7739ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = data_handler.get_notes()\n",
    "n_vocab = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecdb6915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Created!\n"
     ]
    }
   ],
   "source": [
    "music_gen = MusicGenerator()\n",
    "model = music_gen.load_model()\n",
    "prediction_output = music_gen.generate_music(model=model, notes=notes, n_vocab=n_vocab)\n",
    "music_gen.create_midi(prediction_output)\n",
    "print(\"Output Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fe58abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = MusicPlayer('Output/output.mid')\n",
    "\n",
    "# player.play_midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f360b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
